---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I’m a Research Scientist at Snowflake AI Research, where I train reasoning models and LLM agents, especially for structured data. Before that, I was a Research Scientist on Bytedance’s Seed‑Foundation‑Code team.

I earned my Ph.D. from the University of Illinois at Urbana‑Champaign under [Prof. Ruoyu Sun](https://ruoyus.github.io/), with co‑advising from [Prof. Naira Hovakimyan](http://naira.mechse.illinois.edu/). In my first year I collaborated with [Prof. Justin Sirignano](https://www.maths.ox.ac.uk/people/justin.sirignano) on deep‑learning for computational fluid dynamics (CFD), and during my master’s studies I worked with [Prof. Kyle Smith](https://kcsmith.mechse.illinois.edu/) on numerical simulation for energy storage systems.

**Research interests:** Reasoning Models; Agent; Efficient Deep Learning; Natural Language Processing; Computer Vision; Numerical Methods.

**Hiring**: [Snowflake AI Research](https://www.snowflake.com/en/product/ai/ai-research/) is seeking research scientist interns for remote, long-term positions (3-6 months, part-time) starting August 2025. Projects include:

- Post‑training tool‑augmented LLMs

- Development of personalized Text‑to‑SQL models

- Deep Research on structured data

- Developing and training of data‑science agents

If  you are interested, don't hesitate to send your resume to yite.wang@snowflake.com .

## News

**[April. 2025]** I have joined Snowflake AI Research working on reasoning models and LLM Agents.

**[May. 2024]** I have joined ByteDance Seed-Foundation-Code as a Research Scientist working on LLM for code.

**[Mar. 2024]** I have successfully defended my Ph.D. thesis!

**[Jan. 2024]** Our paper on model expansion is accepted to ICLR'2024!

**[Oct. 2023]** I have received the NeurIPS 2023 Scholar Award!

**[Sept. 2023]** Our paper about dynamic sparse training for GANs is accepted to NeurIPS'2023!

**[Jan. 2023]** Our paper about foresight pruning is accepted to ICLR'2023!

**[March. 2022]** Our paper about neural architecture search for meta learning is accpeted to CVPR'2022!

## Publications

( $\dagger$ denotes to equal contribution)

- **Fullstack bench: Evaluating llms as full stack coder** [[arXiv](https://arxiv.org/abs/2412.00535)]
  
  Seed-Foundation-Code Team, ByteDance

- **Designing Large Foundation Models for Efficient Training and Inference: A Survey** [[arxiv](https://arxiv.org/abs/2412.00535)]
  
  Dong Liu, Yanxuan Yu, **<u>Yite Wang</u>**, Jing Wu, Zhongwei Wan, Sina Alinejad, Benjamin Lengerich, Ying Nian Wu
* **LEMON: Lossless model expansion** [[arXiv](https://arxiv.org/abs/2310.07999), [code](https://github.com/YiteWang/lemon-pytorch)]
  
  **<u>Yite Wang</u>**, Jiahao Su, Hanlin Lu, Cong Xie, Tianyi Liu, Jianbo Yuan, Haibin Lin, Ruoyu Sun, Hongxia Yang
  
  ***ICLR'2024**：International Conference on Learning Representations*
- **Balanced Training for Sparse GANs** [[arXiv](https://arxiv.org/abs/2302.14670), [page](https://neurips.cc/virtual/2023/poster/70078), [code](https://github.com/YiteWang/ADAPT)]
  
  **<u>Yite Wang</u>**$\dagger$, Jing Wu$\dagger$, Naira Hovakimyan, Ruoyu Sun
  
  ***NeurIPS'2023**: Neural Information Processing Systems* 

- **NTK-SAP: Improving neural network pruning by aligning training dynamics** [[arXiv](https://arxiv.org/abs/2304.02840), [page](https://iclr.cc/virtual/2023/poster/12107), [code](https://github.com/YiteWang/NTK-SAP)]
  
  **<u>Yite Wang</u>**, Dawei Li, Ruoyu Sun
  
  ***ICLR'2023**: International Conference on Learning Representations* 

- **Global Convergence of MAML and Theory-Inspired Neural Architecture Search for Few-Shot Learning** [[arXiv](https://arxiv.org/abs/2203.09137), [code](https://github.com/YiteWang/MetaNTK-NAS)]
  
  Haoxiang Wang$\dagger$, **<u>Yite Wang</u>**$\dagger$, Ruoyu Sun, Bo Li
  
  ***CVPR'2022**: The IEEE/CVF Computer Vision and Pattern Recognition Conference*

- **Numerical investigation of convective transport in redox flow battery tanks: Using baffles to increase utilization** [[paper](https://www.sciencedirect.com/science/article/abs/pii/S2352152X19303469)]
  
  **<u>Yite Wang</u>**, Kyle Smith
  
  ***Journal of Energy Storage*** 
